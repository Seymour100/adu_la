{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Los-Angeles-City-Civic-Data\" data-toc-modified-id=\"Los-Angeles-City-Civic-Data-1\">Los Angeles City Civic Data</a></span></li><li><span><a href=\"#Building-Permit-Data\" data-toc-modified-id=\"Building-Permit-Data-2\">Building Permit Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Socrata-API-and-managing-the-rate-limits\" data-toc-modified-id=\"Socrata-API-and-managing-the-rate-limits-2.1\">Socrata API and managing the rate limits</a></span></li><li><span><a href=\"#Inspecting-and-Cleaning-the-Data\" data-toc-modified-id=\"Inspecting-and-Cleaning-the-Data-2.2\">Inspecting and Cleaning the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Checking-for-Duplicates\" data-toc-modified-id=\"Checking-for-Duplicates-2.2.1\">Checking for Duplicates</a></span></li><li><span><a href=\"#Census-Tract\" data-toc-modified-id=\"Census-Tract-2.2.2\">Census Tract</a></span></li><li><span><a href=\"#Assessor's-Parcel-Number\" data-toc-modified-id=\"Assessor's-Parcel-Number-2.2.3\">Assessor's Parcel Number</a></span></li><li><span><a href=\"#Geospatial-Data\" data-toc-modified-id=\"Geospatial-Data-2.2.4\">Geospatial Data</a></span></li></ul></li></ul></li><li><span><a href=\"#Census-Data:-Merge-on-census_tract\" data-toc-modified-id=\"Census-Data:-Merge-on-census_tract-3\">Census Data: Merge on census_tract</a></span></li><li><span><a href=\"#LA-County-Parcel-Data-and-Joining-on-APN\" data-toc-modified-id=\"LA-County-Parcel-Data-and-Joining-on-APN-4\">LA County Parcel Data and Joining on APN</a></span></li><li><span><a href=\"#Geospatial-Data-and-Joining-on-Geometries\" data-toc-modified-id=\"Geospatial-Data-and-Joining-on-Geometries-5\">Geospatial Data and Joining on Geometries</a></span></li><li><span><a href=\"#Putting-it-all-together-into-an-ETL-class\" data-toc-modified-id=\"Putting-it-all-together-into-an-ETL-class-6\">Putting it all together into an ETL class</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Los Angeles City Civic Data\n",
    "\n",
    "Trying to perform any sort of analysis or modeling of LA City land use issues is not just a exercise in exploratory data analysis and model building, its an exercise in data discovery and extraction. When I first came across <a href='https://data.lacity.org'>https://data.lacity.org</a>, with its over 1,000 datasets I thought that I would have pretty much everything I needed in one location to model the probabilty that an ADU (accesory dwelling unit), once someone applies for a permit, would be completed (see my post \"Predicting ADU Completion\"). Not so. \n",
    "\n",
    "Taking my clues about which factors influence ADU development projects from a design and architecture <a href='https://www.kcrw.com/culture/shows/design-and-architecture/dodger-stadium-upgrades-an-adu-is-born/at-long-last-an-adu-is-born-in-highland-park'>segment</a> on my local public radio station KCRW I soon realized that I would need to source data about building permits, parcel sizes, median incomes, historic preservation overlay zones and hillside ordinances. All of these datasets are maintained by different government entities. Some of the municipal services that we enjoy are provisioned by the city and others by the county. They each have their own data hubs (LA county's is <a href='https://data.lacounty.gov'>data.lacounty.gov</a>). They both contain some demographic data from the US Census, but without knowing how frequently it is updated I thought it better to source that data from the Census Bureau itself.\n",
    "\n",
    "While it was quite straight forward to download some datasets, I found the API's provided for others to be querky at best. And then when the time came to merge them  together I often found that the most logical common key shared by two datasets to be represented differently in each. This post is meant to be a roadmap for anyone wanting to take advantage of the trove of publicly available data for the city of Los Angeles in order to understand, and improve, what makes our city tick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Permit Data\n",
    "Luckily I had found on the LA City data hub what looked like to be a curated dataset of ADU permits applied for and issued during the six months between July 1, 2017 and December 31, 2017. At the onset of this project I though I could create my own dataset of ADU projoects from the larger dataset of all LA city building permits, but I don't believe there was a single identifying code for ADU's in LA's permitting system. Also, the ADU may be part of a larger project and permitted as such. Thankfully some helpful soul in the LA City IT department identified six months of permits for ADU's, most likely for someone's study, and isolated them into their own public data set. The status of all the permits in this set are updated once a week since their issuance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socrata API and managing the rate limits\n",
    "The ADU dataset that I'm going to work with contains geospatial data that will have to be manipulated later, although not a geospatial databaser per se. Many of the non-geospatial datasets I've run across on municipal sites use the Socrata API. There is quite a bit of documentation available, even regarding this <a href='https://dev.socrata.com/foundry/data.lacity.org/r9zn-9ttc'>dataset</a> specifically (scroll down to the bottom of the page and click on the \"Python Pandas\" tab). When I first downloaded this data set I found that the rate limiting employed would not allow me to extract the entire dataset in one go. Given that set is fairly small (7,778 records) I found the rate limiting to be rather sever.\n",
    "\n",
    "In order to get around this issue, and pull the entire dataset directly into memory, I had to write a loop that extracted chunks of it at a time. This knowledge came from this very helpful <a href='http://holowczak.com/getting-started-with-nyc-opendata-and-the-socrata-api/5/'>post</a> (see \"Paging Through Data\") by <a href='http://holowczak.com/about-me/'>Rich Holowczak</a> who was having the same issue with New York City data. Good to know that I'm not alone.\n",
    "\n",
    "When I returned to this data set almost a year later I found that I could pull the entire data set in one, clean query. Thank you again to whoever it was in the LA City IT department that improved this process.\n",
    "\n",
    "If you don't already have the sodapy package installed, please do so now. It's an easy pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:43.767131Z",
     "start_time": "2021-04-10T20:27:42.450823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import censusdata\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:43.783459Z",
     "start_time": "2021-04-10T20:27:43.771605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import your api_token created for the LA City Datahub, as well as your username and password\n",
    "with open('./data/la_city_key', 'r') as f:\n",
    "    api_token = f.readline().replace('\\n','')\n",
    "with open('./data/la_city_username', 'r') as f:\n",
    "    usrn = f.readline().replace('\\n','')\n",
    "with open('./data/la_city_password', 'r') as f:\n",
    "    psswrd = f.readline().replace('\\n','')\n",
    "\n",
    "# The url we're using is the below\n",
    "url = \"data.lacity.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:43.798263Z",
     "start_time": "2021-04-10T20:27:43.791566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the Socrata client\n",
    "client = Socrata(url, api_token, username=usrn, password=psswrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:45.166186Z",
     "start_time": "2021-04-10T20:27:43.808506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': '7778'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dataset we're requesting. In this case it's the \"ADU permits 7/1/17-12/31/17(JB2)\" db whose unique\n",
    "# identifier is r9zn-9ttc. Then determine how many records are in the data set using the Socrata client and the \n",
    "# SQL count query\n",
    "adu_permits = \"r9zn-9ttc\"\n",
    "record_count = client.get(adu_permits, select=\"COUNT(*)\")\n",
    "record_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:49.420793Z",
     "start_time": "2021-04-10T20:27:45.170852Z"
    }
   },
   "outputs": [],
   "source": [
    "# There are 7,778 records in the set, so I'm setting the limit to 8000 in my first attemp to download the dataset\n",
    "data_raw = client.get('r9zn-9ttc', limit=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query took less than 5 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:49.644717Z",
     "start_time": "2021-04-10T20:27:49.423471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a pandas DataFrame out of the raw data\n",
    "data_df = pd.DataFrame(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, downloading the data a year ago required me to do so in chucks. I going to put the code I used then below just for reference, in the event I need to go back to that method of data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:49.674724Z",
     "start_time": "2021-04-10T20:27:49.650425Z"
    }
   },
   "outputs": [],
   "source": [
    "# client.timeout = 50\n",
    "# start = 0\n",
    "# chunk_size = 1000\n",
    "# data = []\n",
    "# while True:\n",
    "#      data.extend(client.get(adu_permits, offset=start, limit=chunk_size))\n",
    "#      start = start + chunk_size\n",
    "#      if (start > int(record_count[0]['count']) ):\n",
    "#         break\n",
    "        \n",
    "# data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:49.993293Z",
     "start_time": "2021-04-10T20:27:49.684382Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting the index to False so I don't save the index as a column\n",
    "data_df.to_csv('./data/adu_records.csv', index=False, float_format=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would save this file locally so that I didn't have to do this every time I want to work on it back when I had to extract it in small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.005342Z",
     "start_time": "2021-04-10T20:27:49.999312Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_df = pd.read_csv('./data/adu_records.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.118224Z",
     "start_time": "2021-04-10T20:27:50.016813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7778 entries, 0 to 7777\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                   Non-Null Count  Dtype \n",
      "---  ------                                   --------------  ----- \n",
      " 0   zip_code                                 7778 non-null   object\n",
      " 1   address_end                              7778 non-null   object\n",
      " 2   work_description                         7778 non-null   object\n",
      " 3   :@computed_region_qz3q_ghft              6773 non-null   object\n",
      " 4   :@computed_region_k96s_3jcv              6773 non-null   object\n",
      " 5   reference_old_permit                     7778 non-null   object\n",
      " 6   principal_first_name                     3856 non-null   object\n",
      " 7   :@computed_region_kqwf_mjcx              6773 non-null   object\n",
      " 8   census_tract                             7778 non-null   object\n",
      " 9   permit_category                          7778 non-null   object\n",
      " 10  latest_status                            7778 non-null   object\n",
      " 11  initiating_office                        7778 non-null   object\n",
      " 12  :@computed_region_2dna_qi2s              6446 non-null   object\n",
      " 13  assessor_parcel                          7778 non-null   object\n",
      " 14  applicant_first_name                     7639 non-null   object\n",
      " 15  zone                                     7772 non-null   object\n",
      " 16  assessor_book                            7778 non-null   object\n",
      " 17  contractor_state                         3608 non-null   object\n",
      " 18  license_expiration_date                  4749 non-null   object\n",
      " 19  :@computed_region_tatf_ua23              6773 non-null   object\n",
      " 20  principal_middle_name                    2411 non-null   object\n",
      " 21  license_type                             7778 non-null   object\n",
      " 22  valuation                                7778 non-null   object\n",
      " 23  pcis_permit                              7778 non-null   object\n",
      " 24  applicant_relationship                   7651 non-null   object\n",
      " 25  contractor_city                          3609 non-null   object\n",
      " 26  address_start                            7778 non-null   object\n",
      " 27  street_name                              7778 non-null   object\n",
      " 28  street_suffix                            7692 non-null   object\n",
      " 29  street_direction                         7739 non-null   object\n",
      " 30  status_date                              7778 non-null   object\n",
      " 31  applicant_last_name                      6489 non-null   object\n",
      " 32  principal_last_name                      3843 non-null   object\n",
      " 33  license                                  7778 non-null   object\n",
      " 34  issue_date                               7778 non-null   object\n",
      " 35  assessor_page                            7778 non-null   object\n",
      " 36  contractors_business_name                7765 non-null   object\n",
      " 37  tract                                    7759 non-null   object\n",
      " 38  lot                                      7745 non-null   object\n",
      " 39  permit_sub_type                          7778 non-null   object\n",
      " 40  council_district                         7778 non-null   object\n",
      " 41  location_1                               6773 non-null   object\n",
      " 42  contractor_address                       3726 non-null   object\n",
      " 43  permit_type                              7778 non-null   object\n",
      " 44  applicant_address_1                      5383 non-null   object\n",
      " 45  applicant_address_3                      5111 non-null   object\n",
      " 46  applicant_address_2                      1318 non-null   object\n",
      " 47  unit_range_start                         72 non-null     object\n",
      " 48  floor_area_l_a_building_code_definition  4337 non-null   object\n",
      " 49  of_residential_dwelling_units            1896 non-null   object\n",
      " 50  floor_area_l_a_zoning_code_definition    4122 non-null   object\n",
      " 51  of_stories                               4017 non-null   object\n",
      " 52  applicant_business_name                  543 non-null    object\n",
      " 53  :@computed_region_ur2y_g4cx              2071 non-null   object\n",
      " 54  address_fraction_start                   234 non-null    object\n",
      " 55  address_fraction_end                     321 non-null    object\n",
      " 56  occupancy                                113 non-null    object\n",
      " 57  block                                    1470 non-null   object\n",
      " 58  unit_range_end                           5 non-null      object\n",
      " 59  project_number                           5 non-null      object\n",
      " 60  suffix_direction                         7 non-null      object\n",
      "dtypes: object(61)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# The first step I take with any new data set is just to look down the list of all of the data types in the set\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first, most obvious issue with this dataset is the number of columns - 61. The description of the <a href=\"https://data.lacity.org/City-Infrastructure-Service-Requests/ADU-permits-7-1-17-12-31-17-JB2-/r9zn-9ttc\">dataset</a> on data.lacity.org indicates that there should be 56 columns. So by inspection we see that for some reason there are 6 additional columns that begin with an \":@\" symbol. Also, the column \"event\" isn't included in the download that is listed on the site. Let's have a look at the \"@ ...\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.165727Z",
     "start_time": "2021-04-10T20:27:50.124488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:@computed_region_qz3q_ghft</th>\n",
       "      <th>:@computed_region_k96s_3jcv</th>\n",
       "      <th>:@computed_region_kqwf_mjcx</th>\n",
       "      <th>:@computed_region_2dna_qi2s</th>\n",
       "      <th>:@computed_region_tatf_ua23</th>\n",
       "      <th>:@computed_region_ur2y_g4cx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23448</td>\n",
       "      <td>493</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23448</td>\n",
       "      <td>493</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23673</td>\n",
       "      <td>371</td>\n",
       "      <td>9</td>\n",
       "      <td>93</td>\n",
       "      <td>598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  :@computed_region_qz3q_ghft :@computed_region_k96s_3jcv  \\\n",
       "0                       23448                         493   \n",
       "1                       23448                         493   \n",
       "2                         NaN                         NaN   \n",
       "3                       23673                         371   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "  :@computed_region_kqwf_mjcx :@computed_region_2dna_qi2s  \\\n",
       "0                          11                           1   \n",
       "1                          11                           1   \n",
       "2                         NaN                         NaN   \n",
       "3                           9                          93   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "  :@computed_region_tatf_ua23 :@computed_region_ur2y_g4cx  \n",
       "0                         619                         NaN  \n",
       "1                         619                         NaN  \n",
       "2                         NaN                         NaN  \n",
       "3                         598                         NaN  \n",
       "4                         NaN                         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[[':@computed_region_qz3q_ghft',\n",
    "         ':@computed_region_k96s_3jcv',\n",
    "         ':@computed_region_kqwf_mjcx',\n",
    "         ':@computed_region_2dna_qi2s',\n",
    "         ':@computed_region_tatf_ua23',\n",
    "         ':@computed_region_ur2y_g4cx']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns do not look like a recognizable value, and since they are not part of the data descriptions on the LA City Datahub site, I'm going to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.251921Z",
     "start_time": "2021-04-10T20:27:50.170890Z"
    }
   },
   "outputs": [],
   "source": [
    "del data_df[':@computed_region_qz3q_ghft']\n",
    "del data_df[':@computed_region_k96s_3jcv']\n",
    "del data_df[':@computed_region_kqwf_mjcx']\n",
    "del data_df[':@computed_region_2dna_qi2s']\n",
    "del data_df[':@computed_region_tatf_ua23']\n",
    "del data_df[':@computed_region_ur2y_g4cx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Duplicates\n",
    "One of the first item I check for is duplicate records. I'll do this here with the permit number as specified by the <a href='https://dev.socrata.com/foundry/data.lacity.org/r9zn-9ttc'>data dictionary</a> of this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.273191Z",
     "start_time": "2021-04-10T20:27:50.256680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7778\n",
       "Name: pcis_permit, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['pcis_permit'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I appears that there are no duplicates in the set. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Tract\n",
    "The census tract number is one of the more granular levels of census data, much more so that zip codes for the most part. When looking at a single city, performing analysis at the census tract level provides much more nuance than the zip code level. Often in the city of Los Angeles a Neighborhood Council, the lowest level of city government, contains more than one census tract. I have seen data available for and even smaller footprint, the block level, but not as consistently as census tract.\n",
    "\n",
    "Given the importance of census tract level data, let's examine the 'census tract' field in the ADU data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.302352Z",
     "start_time": "2021-04-10T20:27:50.281444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1998.00\n",
       "1    1998.00\n",
       "2    1873.00\n",
       "3    1836.20\n",
       "4    1082.02\n",
       "Name: census_tract, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['census_tract'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census tracks can be expressed in a format that is XXXX.XX where the last two digits take forms such as: 01, 02, 10, 20, etc. I've also seen census tracts written as a six character strings without a period. The first 5 values look good, but let's check the data type for each record, just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.338309Z",
     "start_time": "2021-04-10T20:27:50.309564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'str'>    7778\n",
       "Name: census_tract, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['census_tract'].apply(lambda x: type(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All value are strings, so let's remove the \".\" and create a 6 character value for each record. This will make it easier to join to census data later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.368544Z",
     "start_time": "2021-04-10T20:27:50.348452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Revome the \".\" with a replace method\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: x.replace('.', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that all of the records have the same 6 character length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.434303Z",
     "start_time": "2021-04-10T20:27:50.414926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    7778\n",
       "Name: census_tract, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['census_tract'].apply(lambda x: len(x)).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good - all 7,778 records of 'census_tract' are 6 characters long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessor's Parcel Number\n",
    "The Assessor's Parcel Number, or APN, is another key value that we want to pay special attention to it since is uniquely identifies individual properties. If you've ever paid a property tax bill with a paper check in Los Angeles, you've written the APN number on the return envelop provided. It's a 9 digit number in the format: XXXX-XX-XXX. The first four digits are the assessor's book number, the next two are the assessor's page, and the last three designate the parcel.\n",
    "\n",
    "Inspecting the columns in the ADU dataset we find that the APN number has been recorded in three separate fields, one each for the book, page and parcel. Let's put it back together, with the dashes, so that we have a column that has the full APN number. This will make it easier to merge dataset from other sources, such as LA County, that use the APN as a unique identifier.\n",
    "\n",
    "First let's examine the values in each of the columns to educate ourselves on the format of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.458249Z",
     "start_time": "2021-04-10T20:27:50.440385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assessor_book</th>\n",
       "      <th>assessor_page</th>\n",
       "      <th>assessor_parcel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5211</td>\n",
       "      <td>002</td>\n",
       "      <td>022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5211</td>\n",
       "      <td>002</td>\n",
       "      <td>022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5438</td>\n",
       "      <td>013</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5484</td>\n",
       "      <td>027</td>\n",
       "      <td>012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2701</td>\n",
       "      <td>001</td>\n",
       "      <td>040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  assessor_book assessor_page assessor_parcel\n",
       "0          5211           002             022\n",
       "1          5211           002             022\n",
       "2          5438           013             001\n",
       "3          5484           027             012\n",
       "4          2701           001             040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[['assessor_book','assessor_page','assessor_parcel']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we convert the data set to type str, let's check the data types of each value, just like we did with the census_tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.496410Z",
     "start_time": "2021-04-10T20:27:50.462980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>    7778\n",
      "Name: assessor_book, dtype: int64\n",
      "<class 'str'>    7778\n",
      "Name: assessor_page, dtype: int64\n",
      "<class 'str'>    7778\n",
      "Name: assessor_parcel, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_df['assessor_book'].apply(lambda x: type(x)).value_counts())\n",
    "print(data_df['assessor_page'].apply(lambda x: type(x)).value_counts())\n",
    "print(data_df['assessor_parcel'].apply(lambda x: type(x)).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all looks good, so we'll go ahead and create one record for APN by concatenating each of the individual fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.545978Z",
     "start_time": "2021-04-10T20:27:50.500768Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df['APN'] = data_df['assessor_book']+'-'+data_df['assessor_page']+'-'+data_df['assessor_parcel']\n",
    "del data_df['assessor_book']\n",
    "del data_df['assessor_page']\n",
    "del data_df['assessor_parcel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have found most municipal datasets to be either a be a proper geospatial data set (meaning is stored in a common geospatial file format) or not. When working with geospatial data I would prefer to work with geoJSON's. The JSON format is a staple of the online world and can be used in simple NoSQL databases. Thus, if available I will ususlly download the geoJSON version of the data set. \n",
    "\n",
    "Inspecting the ADU data set we see a column title location, which contains latitude and longitude data, presumably of the parcel where the ADU is to be constructed.\n",
    "\n",
    "Let's take a look at this record since we will need it to merge any data that is stored by defined geographic regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.561122Z",
     "start_time": "2021-04-10T20:27:50.549598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'latitude': '34.06971', 'human_address': '{\"a...\n",
       "1    {'latitude': '34.06971', 'human_address': '{\"a...\n",
       "2                                                  NaN\n",
       "3    {'latitude': '34.11747', 'human_address': '{\"a...\n",
       "4                                                  NaN\n",
       "Name: location_1, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['location_1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a dictionary with lattitude and longitude as a couple of the key, value paris. I'm going to take a look at just one record so I can see the format of it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.573346Z",
     "start_time": "2021-04-10T20:27:50.564992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': '34.06971',\n",
       " 'human_address': '{\"address\": \"\", \"city\": \"\", \"state\": \"\", \"zip\": \"\"}',\n",
       " 'needs_recoding': False,\n",
       " 'longitude': '-118.20629'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['location_1'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes indeed. It's relatively easy to extract, but this is what I meant earlier when I stated that the ADU data set has geospatial data in it, but it isn't a geospatial database. We'll need to extract the latitude and longitude into their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.609035Z",
     "start_time": "2021-04-10T20:27:50.587126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6773"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['latitude'] = data_df['location_1'].apply(lambda x: x['latitude'] if isinstance(x, dict) else None)\n",
    "data_df['latitude'] = data_df['latitude'].astype(float)\n",
    "data_df['latitude'].notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.639387Z",
     "start_time": "2021-04-10T20:27:50.618556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6773"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['longitude'] = data_df['location_1'].apply(lambda x: x['longitude'] if isinstance(x, dict) else None)\n",
    "data_df['longitude'] = data_df['longitude'].astype(float)\n",
    "data_df['longitude'].notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have two columns for geospatial records: latitude and longitude. For now we'll just leave them as type float, and later we will use GeoPandas to convert them into the geo type point. This will enable us to use GeoPandas to determine if a location resides in a certain geographic areas with specific characteristics, and then merge those characteristics into our ADU dataset so that we can use them for modeling.\n",
    "\n",
    "We can remove the location_1 column now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.665324Z",
     "start_time": "2021-04-10T20:27:50.643832Z"
    }
   },
   "outputs": [],
   "source": [
    "del data_df['location_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Data: Merge on census_tract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the data. I'd like to use median household income data in my model. The <a href=\"https://www.census.gov/content/dam/Census/data/developers/api-user-guide/api-guide.pdf\"> Census Data API User Guide</a> is a nice document that explains how their API works, but before writing any Python code I first  use their <a href=\"https://data.census.gov/cedsci/advanced\">GUI</a> query tool to get a feel of what is available. The API User Guide refers you to a their <a href=\"https://www.census.gov/data/developers/updates/new-discovery-tool.html\">Discory Tool</a>, which, unless I'm missing something, is basically a very long list of data sets in various formats. I use the <a href=\"https://api.census.gov/data.html\">html verion</a>. After some research I learned that I want to use the American Community Survey - 5 year data for median income. I go to that table in the Discovery Tool and start looking through the <a href=\"https://api.census.gov/data/2009/acs/acs5/variables.html\">variables</a>. Oh my, a table that is even longer than the previous one. So long that it takes Chrome serval seconds to do a key word search of the page. So I start using command-F to search for the terms \"income\", \"median income\", \"household income\". I finally find what looks to be the correct variable name - B19013.\n",
    "\n",
    "Another way to do this is to use an API wrapper. There are a few out there for US Census data. In fact, at the bottom of the API User Guide they refer you to this <a href=\"https://pypi.org/project/census/0.5/\">one</a>. I however used <a href=\"https://pypi.org/project/CensusData/\">censusdata</a>. I think it is most useful in searching through the census tables. As you will see below, you can query specific words and phrases and it generating a list of tables and names. This was how I locate B19013_001E as the table for household median income.\n",
    "\n",
    "I make a few spot checks against the GUI for specific tracks - they matched! So I am confident that this is the data I should be using.\n",
    "\n",
    "When it comes time to download a dataset of median income for all census tracts in Los Angeles, I decide to use the requests library and not a wrapper. So following the API User Guide I construct the correct URL. I find it helpful to first play around with the syntax in my browser. It is just a quick way to fiddle the url so until it is correct before pulling the data into my notebook with requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.687272Z",
     "start_time": "2021-04-10T20:27:50.674572Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'm not going to run this in this notebook since the output is quite long\n",
    "# censusdata.search('acs5', 2018, 'label', 'household income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:50.986343Z",
     "start_time": "2021-04-10T20:27:50.697656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     | Table                          | Label                                                    | Type \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "B23025_001E  | EMPLOYMENT STATUS FOR THE POPU | !! Estimate Total                                        | int  \n",
      "B23025_002E  | EMPLOYMENT STATUS FOR THE POPU | !! !! Estimate Total In labor force                      | int  \n",
      "B23025_003E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! Estimate Total In labor force Civilian labor fo | int  \n",
      "B23025_004E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! !! Estimate Total In labor force Civilian labor | int  \n",
      "B23025_005E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! !! Estimate Total In labor force Civilian labor | int  \n",
      "B23025_006E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! Estimate Total In labor force Armed Forces      | int  \n",
      "B23025_007E  | EMPLOYMENT STATUS FOR THE POPU | !! !! Estimate Total Not in labor force                  | int  \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# An example of information on educational attainment\n",
    "censusdata.printtable(censusdata.censustable('acs5', '2018', 'B23025'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:51.184642Z",
     "start_time": "2021-04-10T20:27:50.991901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     | Table                          | Label                                                    | Type \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "B23025_001E  | EMPLOYMENT STATUS FOR THE POPU | !! Estimate Total                                        | int  \n",
      "B23025_002E  | EMPLOYMENT STATUS FOR THE POPU | !! !! Estimate Total In labor force                      | int  \n",
      "B23025_003E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! Estimate Total In labor force Civilian labor fo | int  \n",
      "B23025_004E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! !! Estimate Total In labor force Civilian labor | int  \n",
      "B23025_005E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! !! Estimate Total In labor force Civilian labor | int  \n",
      "B23025_006E  | EMPLOYMENT STATUS FOR THE POPU | !! !! !! Estimate Total In labor force Armed Forces      | int  \n",
      "B23025_007E  | EMPLOYMENT STATUS FOR THE POPU | !! !! Estimate Total Not in labor force                  | int  \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# An example of information on employment\n",
    "censusdata.printtable(censusdata.censustable('acs5', '2018', 'B23025'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of data and the number of cross tabulations of that data the the Census Bureau provides is truly incredible. I'm a huge fan. But, getting back to the task at hand, I locate the table for median household income for which I was searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:51.500376Z",
     "start_time": "2021-04-10T20:27:51.220332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     | Table                          | Label                                                    | Type \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "B19013_001E  | MEDIAN HOUSEHOLD INCOME IN THE | !! Estimate Median household income in the past 12 month | int  \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "censusdata.printtable(censusdata.censustable('acs5', 2018, 'B19013'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a note, in the API documentation the NAME refers to the rather cryptic looking variable codes - B19013, etc. It took me a bit to catch on to this. I finally found that this was the golden ticket: https://api.census.gov/data/2019/acs/acs5?get=B19013_001E&for=tract:*&in=state:06&in=county:037\n",
    "\n",
    "And so used it in the requests module to download the data into my notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.892247Z",
     "start_time": "2021-04-10T20:27:51.506713Z"
    }
   },
   "outputs": [],
   "source": [
    "url='https://api.census.gov/data/2019/acs/acs5?get=B19013_001E&for=tract:*&in=state:06&in=county:037'\n",
    "median_income_raw = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.906192Z",
     "start_time": "2021-04-10T20:27:52.896304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_income_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response 200, or in plain English, I got something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.923889Z",
     "start_time": "2021-04-10T20:27:52.910410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B19013_001E', 'state', 'county', 'tract'],\n",
       " ['82917', '06', '037', '482702'],\n",
       " ['114831', '06', '037', '500201'],\n",
       " ['133125', '06', '037', '500202'],\n",
       " ['102875', '06', '037', '500300'],\n",
       " ['53500', '06', '037', '500500'],\n",
       " ['55446', '06', '037', '500900'],\n",
       " ['43929', '06', '037', '501400'],\n",
       " ['102292', '06', '037', '501501'],\n",
       " ['68783', '06', '037', '501802']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it into a json for readability\n",
    "median_income_raw.json()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a list of lists. The first row is the column headers, so make a DataFrame with all rows after the first and use the first row and the columns in the dataframe constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.943034Z",
     "start_time": "2021-04-10T20:27:52.927944Z"
    }
   },
   "outputs": [],
   "source": [
    "median_income_df = pd.DataFrame(data=median_income_raw.json()[1:], columns=median_income_raw.json()[:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.965830Z",
     "start_time": "2021-04-10T20:27:52.948264Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B19013_001E</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82917</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>482702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114831</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133125</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102875</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53500</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  B19013_001E state county   tract\n",
       "0       82917    06    037  482702\n",
       "1      114831    06    037  500201\n",
       "2      133125    06    037  500202\n",
       "3      102875    06    037  500300\n",
       "4       53500    06    037  500500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_income_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:52.989198Z",
     "start_time": "2021-04-10T20:27:52.970019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2346 entries, 0 to 2345\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   B19013_001E  2346 non-null   object\n",
      " 1   state        2346 non-null   object\n",
      " 2   county       2346 non-null   object\n",
      " 3   tract        2346 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 73.4+ KB\n"
     ]
    }
   ],
   "source": [
    "median_income_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.010311Z",
     "start_time": "2021-04-10T20:27:52.994254Z"
    }
   },
   "outputs": [],
   "source": [
    "median_income_df.rename(columns={'B19013_001E':'median_income','tract':'census_tract'}, inplace=True)\n",
    "del median_income_df['state']\n",
    "del median_income_df['county']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the ADU's are in Los Angeles city, and the median income data is for every census tract in Los Angeles county,\n",
    "so by doing a left join of the median income data onto the ADU dataset with the census_tract as the key, I would expect most all of the records to have an associated median income after the merge. Note every record of the 7,778 ADU dataset has a value for census_tract - see .info() at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.219163Z",
     "start_time": "2021-04-10T20:27:53.019699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7778 entries, 0 to 7777\n",
      "Data columns (total 56 columns):\n",
      " #   Column                                   Non-Null Count  Dtype   \n",
      "---  ------                                   --------------  -----   \n",
      " 0   zip_code                                 7778 non-null   object  \n",
      " 1   address_end                              7778 non-null   object  \n",
      " 2   work_description                         7778 non-null   object  \n",
      " 3   reference_old_permit                     7778 non-null   object  \n",
      " 4   principal_first_name                     3856 non-null   object  \n",
      " 5   census_tract                             7778 non-null   object  \n",
      " 6   permit_category                          7778 non-null   object  \n",
      " 7   latest_status                            7778 non-null   object  \n",
      " 8   initiating_office                        7778 non-null   object  \n",
      " 9   applicant_first_name                     7639 non-null   object  \n",
      " 10  zone                                     7772 non-null   object  \n",
      " 11  contractor_state                         3608 non-null   object  \n",
      " 12  license_expiration_date                  4749 non-null   object  \n",
      " 13  principal_middle_name                    2411 non-null   object  \n",
      " 14  license_type                             7778 non-null   object  \n",
      " 15  valuation                                7778 non-null   object  \n",
      " 16  pcis_permit                              7778 non-null   object  \n",
      " 17  applicant_relationship                   7651 non-null   object  \n",
      " 18  contractor_city                          3609 non-null   object  \n",
      " 19  address_start                            7778 non-null   object  \n",
      " 20  street_name                              7778 non-null   object  \n",
      " 21  street_suffix                            7692 non-null   object  \n",
      " 22  street_direction                         7739 non-null   object  \n",
      " 23  status_date                              7778 non-null   object  \n",
      " 24  applicant_last_name                      6489 non-null   object  \n",
      " 25  principal_last_name                      3843 non-null   object  \n",
      " 26  license                                  7778 non-null   object  \n",
      " 27  issue_date                               7778 non-null   object  \n",
      " 28  contractors_business_name                7765 non-null   object  \n",
      " 29  tract                                    7759 non-null   object  \n",
      " 30  lot                                      7745 non-null   object  \n",
      " 31  permit_sub_type                          7778 non-null   object  \n",
      " 32  council_district                         7778 non-null   object  \n",
      " 33  contractor_address                       3726 non-null   object  \n",
      " 34  permit_type                              7778 non-null   object  \n",
      " 35  applicant_address_1                      5383 non-null   object  \n",
      " 36  applicant_address_3                      5111 non-null   object  \n",
      " 37  applicant_address_2                      1318 non-null   object  \n",
      " 38  unit_range_start                         72 non-null     object  \n",
      " 39  floor_area_l_a_building_code_definition  4337 non-null   object  \n",
      " 40  of_residential_dwelling_units            1896 non-null   object  \n",
      " 41  floor_area_l_a_zoning_code_definition    4122 non-null   object  \n",
      " 42  of_stories                               4017 non-null   object  \n",
      " 43  applicant_business_name                  543 non-null    object  \n",
      " 44  address_fraction_start                   234 non-null    object  \n",
      " 45  address_fraction_end                     321 non-null    object  \n",
      " 46  occupancy                                113 non-null    object  \n",
      " 47  block                                    1470 non-null   object  \n",
      " 48  unit_range_end                           5 non-null      object  \n",
      " 49  project_number                           5 non-null      object  \n",
      " 50  suffix_direction                         7 non-null      object  \n",
      " 51  APN                                      7778 non-null   object  \n",
      " 52  latitude                                 6773 non-null   float64 \n",
      " 53  longitude                                6773 non-null   float64 \n",
      " 54  median_income                            7758 non-null   object  \n",
      " 55  _merge                                   7778 non-null   category\n",
      "dtypes: category(1), float64(2), object(53)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Let's perform the merge and see what we get. \n",
    "pd.merge(data_df, median_income_df, on='census_tract', how='left', indicator=True).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite good. Only 20 of the records in the ADU data set did not have a match on census_tract with the median income data from the census bureau. (Total number of records = 7778, number of median_income values = 7758.) So the correction we applied when the cleaned the ADU data set seems to have worked. \n",
    "\n",
    "I have, however, encountered situations where the match is not so good. To examine those cases in more detail I would first perform the same merge, only as an outer join, and then take a look at the individual records that did NOT match in both data sets, since you don't know at the onset where an error may lie.\n",
    "\n",
    "Let's do that here just for practice. I like to use the \"indicator\" flag so that I can monitor the merge. It will produce a column \"_merge\" that indicated where the value for the key came from for each record, either the left table, the right table or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.434009Z",
     "start_time": "2021-04-10T20:27:53.223292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9319 entries, 0 to 9318\n",
      "Data columns (total 56 columns):\n",
      " #   Column                                   Non-Null Count  Dtype   \n",
      "---  ------                                   --------------  -----   \n",
      " 0   zip_code                                 7778 non-null   object  \n",
      " 1   address_end                              7778 non-null   object  \n",
      " 2   work_description                         7778 non-null   object  \n",
      " 3   reference_old_permit                     7778 non-null   object  \n",
      " 4   principal_first_name                     3856 non-null   object  \n",
      " 5   census_tract                             9319 non-null   object  \n",
      " 6   permit_category                          7778 non-null   object  \n",
      " 7   latest_status                            7778 non-null   object  \n",
      " 8   initiating_office                        7778 non-null   object  \n",
      " 9   applicant_first_name                     7639 non-null   object  \n",
      " 10  zone                                     7772 non-null   object  \n",
      " 11  contractor_state                         3608 non-null   object  \n",
      " 12  license_expiration_date                  4749 non-null   object  \n",
      " 13  principal_middle_name                    2411 non-null   object  \n",
      " 14  license_type                             7778 non-null   object  \n",
      " 15  valuation                                7778 non-null   object  \n",
      " 16  pcis_permit                              7778 non-null   object  \n",
      " 17  applicant_relationship                   7651 non-null   object  \n",
      " 18  contractor_city                          3609 non-null   object  \n",
      " 19  address_start                            7778 non-null   object  \n",
      " 20  street_name                              7778 non-null   object  \n",
      " 21  street_suffix                            7692 non-null   object  \n",
      " 22  street_direction                         7739 non-null   object  \n",
      " 23  status_date                              7778 non-null   object  \n",
      " 24  applicant_last_name                      6489 non-null   object  \n",
      " 25  principal_last_name                      3843 non-null   object  \n",
      " 26  license                                  7778 non-null   object  \n",
      " 27  issue_date                               7778 non-null   object  \n",
      " 28  contractors_business_name                7765 non-null   object  \n",
      " 29  tract                                    7759 non-null   object  \n",
      " 30  lot                                      7745 non-null   object  \n",
      " 31  permit_sub_type                          7778 non-null   object  \n",
      " 32  council_district                         7778 non-null   object  \n",
      " 33  contractor_address                       3726 non-null   object  \n",
      " 34  permit_type                              7778 non-null   object  \n",
      " 35  applicant_address_1                      5383 non-null   object  \n",
      " 36  applicant_address_3                      5111 non-null   object  \n",
      " 37  applicant_address_2                      1318 non-null   object  \n",
      " 38  unit_range_start                         72 non-null     object  \n",
      " 39  floor_area_l_a_building_code_definition  4337 non-null   object  \n",
      " 40  of_residential_dwelling_units            1896 non-null   object  \n",
      " 41  floor_area_l_a_zoning_code_definition    4122 non-null   object  \n",
      " 42  of_stories                               4017 non-null   object  \n",
      " 43  applicant_business_name                  543 non-null    object  \n",
      " 44  address_fraction_start                   234 non-null    object  \n",
      " 45  address_fraction_end                     321 non-null    object  \n",
      " 46  occupancy                                113 non-null    object  \n",
      " 47  block                                    1470 non-null   object  \n",
      " 48  unit_range_end                           5 non-null      object  \n",
      " 49  project_number                           5 non-null      object  \n",
      " 50  suffix_direction                         7 non-null      object  \n",
      " 51  APN                                      7778 non-null   object  \n",
      " 52  latitude                                 6773 non-null   float64 \n",
      " 53  longitude                                6773 non-null   float64 \n",
      " 54  median_income                            9299 non-null   object  \n",
      " 55  _merge                                   9319 non-null   category\n",
      "dtypes: category(1), float64(2), object(53)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test = pd.merge(data_df, median_income_df, on='census_tract', how='outer', indicator=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have here is a merged dataset with 9319 records. In order to understand the output I keep the chart below handy as a nemonic to remember the basic permutations that are performed with outer joins. Here you see that the 9319 records are made up of:\n",
    "1. Some number of records that matched on census_tract, so the records from the ADU dataset and those from the median income dataset became one\n",
    "2. Some number of ADU records that had a census_tract that wasn't in the median income dataset, and \n",
    "3. Some number of median income records that had a census_tract that wasn't in the ADU data set.\n",
    "\n",
    "\n",
    "[diagram]\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.472961Z",
     "start_time": "2021-04-10T20:27:53.446026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code                                      0\n",
       "address_end                                   0\n",
       "work_description                              0\n",
       "reference_old_permit                          0\n",
       "principal_first_name                          0\n",
       "census_tract                               1541\n",
       "permit_category                               0\n",
       "latest_status                                 0\n",
       "initiating_office                             0\n",
       "applicant_first_name                          0\n",
       "zone                                          0\n",
       "contractor_state                              0\n",
       "license_expiration_date                       0\n",
       "principal_middle_name                         0\n",
       "license_type                                  0\n",
       "valuation                                     0\n",
       "pcis_permit                                   0\n",
       "applicant_relationship                        0\n",
       "contractor_city                               0\n",
       "address_start                                 0\n",
       "street_name                                   0\n",
       "street_suffix                                 0\n",
       "street_direction                              0\n",
       "status_date                                   0\n",
       "applicant_last_name                           0\n",
       "principal_last_name                           0\n",
       "license                                       0\n",
       "issue_date                                    0\n",
       "contractors_business_name                     0\n",
       "tract                                         0\n",
       "lot                                           0\n",
       "permit_sub_type                               0\n",
       "council_district                              0\n",
       "contractor_address                            0\n",
       "permit_type                                   0\n",
       "applicant_address_1                           0\n",
       "applicant_address_3                           0\n",
       "applicant_address_2                           0\n",
       "unit_range_start                              0\n",
       "floor_area_l_a_building_code_definition       0\n",
       "of_residential_dwelling_units                 0\n",
       "floor_area_l_a_zoning_code_definition         0\n",
       "of_stories                                    0\n",
       "applicant_business_name                       0\n",
       "address_fraction_start                        0\n",
       "address_fraction_end                          0\n",
       "occupancy                                     0\n",
       "block                                         0\n",
       "unit_range_end                                0\n",
       "project_number                                0\n",
       "suffix_direction                              0\n",
       "APN                                           0\n",
       "latitude                                      0\n",
       "longitude                                     0\n",
       "median_income                              1541\n",
       "_merge                                     1541\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of median income records that didn't find a match of census_tract in the ADU records\n",
    "test[test['_merge']=='right_only'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.494495Z",
     "start_time": "2021-04-10T20:27:53.477675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code                                   20\n",
       "address_end                                20\n",
       "work_description                           20\n",
       "reference_old_permit                       20\n",
       "principal_first_name                       10\n",
       "census_tract                               20\n",
       "permit_category                            20\n",
       "latest_status                              20\n",
       "initiating_office                          20\n",
       "applicant_first_name                       20\n",
       "zone                                       18\n",
       "contractor_state                            5\n",
       "license_expiration_date                     7\n",
       "principal_middle_name                       6\n",
       "license_type                               20\n",
       "valuation                                  20\n",
       "pcis_permit                                20\n",
       "applicant_relationship                     19\n",
       "contractor_city                             5\n",
       "address_start                              20\n",
       "street_name                                20\n",
       "street_suffix                              20\n",
       "street_direction                           20\n",
       "status_date                                20\n",
       "applicant_last_name                        17\n",
       "principal_last_name                         9\n",
       "license                                    20\n",
       "issue_date                                 20\n",
       "contractors_business_name                  20\n",
       "tract                                      20\n",
       "lot                                        20\n",
       "permit_sub_type                            20\n",
       "council_district                           20\n",
       "contractor_address                          8\n",
       "permit_type                                20\n",
       "applicant_address_1                        14\n",
       "applicant_address_3                        12\n",
       "applicant_address_2                         1\n",
       "unit_range_start                            0\n",
       "floor_area_l_a_building_code_definition    13\n",
       "of_residential_dwelling_units               4\n",
       "floor_area_l_a_zoning_code_definition      11\n",
       "of_stories                                 12\n",
       "applicant_business_name                     3\n",
       "address_fraction_start                      0\n",
       "address_fraction_end                        0\n",
       "occupancy                                   0\n",
       "block                                       0\n",
       "unit_range_end                              0\n",
       "project_number                              0\n",
       "suffix_direction                            0\n",
       "APN                                        20\n",
       "latitude                                   16\n",
       "longitude                                  16\n",
       "median_income                               0\n",
       "_merge                                     20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of ADU records that didn't find a match of census_tract in the median income records\n",
    "test[test['_merge']=='left_only'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.624367Z",
     "start_time": "2021-04-10T20:27:53.499733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zip_code                                   7758\n",
       "address_end                                7758\n",
       "work_description                           7758\n",
       "reference_old_permit                       7758\n",
       "principal_first_name                       3846\n",
       "census_tract                               7758\n",
       "permit_category                            7758\n",
       "latest_status                              7758\n",
       "initiating_office                          7758\n",
       "applicant_first_name                       7619\n",
       "zone                                       7754\n",
       "contractor_state                           3603\n",
       "license_expiration_date                    4742\n",
       "principal_middle_name                      2405\n",
       "license_type                               7758\n",
       "valuation                                  7758\n",
       "pcis_permit                                7758\n",
       "applicant_relationship                     7632\n",
       "contractor_city                            3604\n",
       "address_start                              7758\n",
       "street_name                                7758\n",
       "street_suffix                              7672\n",
       "street_direction                           7719\n",
       "status_date                                7758\n",
       "applicant_last_name                        6472\n",
       "principal_last_name                        3834\n",
       "license                                    7758\n",
       "issue_date                                 7758\n",
       "contractors_business_name                  7745\n",
       "tract                                      7739\n",
       "lot                                        7725\n",
       "permit_sub_type                            7758\n",
       "council_district                           7758\n",
       "contractor_address                         3718\n",
       "permit_type                                7758\n",
       "applicant_address_1                        5369\n",
       "applicant_address_3                        5099\n",
       "applicant_address_2                        1317\n",
       "unit_range_start                             72\n",
       "floor_area_l_a_building_code_definition    4324\n",
       "of_residential_dwelling_units              1892\n",
       "floor_area_l_a_zoning_code_definition      4111\n",
       "of_stories                                 4005\n",
       "applicant_business_name                     540\n",
       "address_fraction_start                      234\n",
       "address_fraction_end                        321\n",
       "occupancy                                   113\n",
       "block                                      1470\n",
       "unit_range_end                                5\n",
       "project_number                                5\n",
       "suffix_direction                              7\n",
       "APN                                        7758\n",
       "latitude                                   6757\n",
       "longitude                                  6757\n",
       "median_income                              7758\n",
       "_merge                                     7758\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of records that matched on census_tract\n",
    "test[test['_merge']=='both'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of these three calculation should equal the maximum total number of records obtain from the outer merge, and in fact, they do!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.646257Z",
     "start_time": "2021-04-10T20:27:53.629940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9319"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 + 1541 + 7758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's take a deep look at the 20 unmatched records from the ADU (left) data set that didn't find a match with the median income data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.675535Z",
     "start_time": "2021-04-10T20:27:53.654666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "930401    14\n",
       "192400     2\n",
       "195900     1\n",
       "269600     1\n",
       "219900     1\n",
       "120000     1\n",
       "Name: census_tract, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the 20 unmatched records\n",
    "test[test['_merge']=='left_only']['census_tract'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are only 6 unique census_tracts that don't have a matching value in the median income data set. Let's take a look at each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.734109Z",
     "start_time": "2021-04-10T20:27:53.683312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_start</th>\n",
       "      <th>street_direction</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>suffix_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>23009</td>\n",
       "      <td>W</td>\n",
       "      <td>BURBANK</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>23063</td>\n",
       "      <td>W</td>\n",
       "      <td>CANZONET</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>5235</td>\n",
       "      <td>N</td>\n",
       "      <td>WOODLAKE</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>23236</td>\n",
       "      <td>W</td>\n",
       "      <td>CANZONET</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>23211</td>\n",
       "      <td>W</td>\n",
       "      <td>MARIANO</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>22952</td>\n",
       "      <td>W</td>\n",
       "      <td>OSTRONIC</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>22946</td>\n",
       "      <td>W</td>\n",
       "      <td>OSTRONIC</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>22923</td>\n",
       "      <td>W</td>\n",
       "      <td>OSTRONIC</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>23035</td>\n",
       "      <td>W</td>\n",
       "      <td>LEONORA</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>23016</td>\n",
       "      <td>W</td>\n",
       "      <td>LEONORA</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>22915</td>\n",
       "      <td>W</td>\n",
       "      <td>BURBANK</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>22915</td>\n",
       "      <td>W</td>\n",
       "      <td>BURBANK</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>5427</td>\n",
       "      <td>N</td>\n",
       "      <td>FENWOOD</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>23018</td>\n",
       "      <td>W</td>\n",
       "      <td>BURBANK</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     address_start street_direction street_name street_suffix suffix_direction\n",
       "1756         23009                W     BURBANK          BLVD              NaN\n",
       "1757         23063                W    CANZONET            ST              NaN\n",
       "1758          5235                N    WOODLAKE           AVE              NaN\n",
       "1759         23236                W    CANZONET            ST              NaN\n",
       "1760         23211                W     MARIANO            ST              NaN\n",
       "1761         22952                W    OSTRONIC            DR              NaN\n",
       "1762         22946                W    OSTRONIC            DR              NaN\n",
       "1763         22923                W    OSTRONIC            DR              NaN\n",
       "1764         23035                W     LEONORA            DR              NaN\n",
       "1765         23016                W     LEONORA            DR              NaN\n",
       "1766         22915                W     BURBANK          BLVD              NaN\n",
       "1767         22915                W     BURBANK          BLVD              NaN\n",
       "1768          5427                N     FENWOOD           AVE              NaN\n",
       "1769         23018                W     BURBANK          BLVD              NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['census_tract']=='930401'][['address_start','street_direction', 'street_name','street_suffix', 'suffix_direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Google Maps and the US Census Bureau's GUI query tool I find this is mis-coded in the ADU data. It should be 137000. All of the streets above are in that tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.783677Z",
     "start_time": "2021-04-10T20:27:53.759028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_start</th>\n",
       "      <th>street_direction</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>suffix_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>15126</td>\n",
       "      <td>W</td>\n",
       "      <td>BURTON</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     address_start street_direction street_name street_suffix suffix_direction\n",
       "7626         15126                W      BURTON            ST              NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['census_tract']=='120000'][['address_start','street_direction', 'street_name','street_suffix', 'suffix_direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various combinations of Burton St in Los Angeles. By looking at Google Maps and the US Census Bureau's GUI query tool, this street address is only valid without the \"W\" prefix but the 120001 census tract does have a Burton St, just not one with this street number. So it is difficult to determine where the error lies, in the census_tract or the address. Did someone use the wrong address when they looked up the census_tract, when it should be totally different, or did they look up the street address wrong when they recorded it, and then got the census_tract wrong by one digit. Given that we cannot really be sure, I'm going to leave these records as unmatched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.821630Z",
     "start_time": "2021-04-10T20:27:53.793696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_start</th>\n",
       "      <th>street_direction</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>suffix_direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>600</td>\n",
       "      <td>N</td>\n",
       "      <td>PLYMOUTH</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6258</th>\n",
       "      <td>600</td>\n",
       "      <td>N</td>\n",
       "      <td>PLYMOUTH</td>\n",
       "      <td>BLVD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     address_start street_direction street_name street_suffix suffix_direction\n",
       "6257           600                N    PLYMOUTH          BLVD              NaN\n",
       "6258           600                N    PLYMOUTH          BLVD              NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['census_tract']=='192400'][['address_start','street_direction', 'street_name','street_suffix', 'suffix_direction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again using Google Maps and the US Census Bureau's GUI query tool I find that this is mis-coded in the ADU data. It should be 192410. This address is in that tract.\n",
    "\n",
    "Following the same process for the remaining 3 census_tract values I find that they are simply incorrect in the ADU data set. \n",
    "\n",
    "The correction are as follows:\n",
    "- 219900 should be 219902\n",
    "- 195900 should be 195903\n",
    "- 269200 should be 269601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.876007Z",
     "start_time": "2021-04-10T20:27:53.834891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Correct census_tract errors in the ADU data set\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: '137000' if x=='930401' else x)\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: '192410' if x=='192400' else x)\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: '219902' if x=='219900' else x)\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: '195903' if x=='195900' else x)\n",
    "data_df['census_tract'] = data_df['census_tract'].apply(lambda x: '269201' if x=='269600' else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can now add the median income data to the DataFrame we want to use for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.915289Z",
     "start_time": "2021-04-10T20:27:53.882519Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.merge(data_df, median_income_df, on='census_tract', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T15:51:55.457781Z",
     "start_time": "2021-03-14T15:51:55.442112Z"
    }
   },
   "source": [
    "It is often said that 80% of the analyst's job is cleaning data, and this is another example of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LA County Parcel Data and Joining on APN\n",
    "One of the features I would like to add to my ADU predictive model is lot size. My intuition is that it is easier to build on a larger lot due to having more space on which to maneuver. For this I've gone to the LA County Geohub where <a href=\"https://geohub.lacity.org/datasets/6d85cb5f5f5641c6aa95203849ca05bb_0?geometry=-128.604%2C32.202%2C-107.994%2C35.396\">detailed parcel records</a> can be found. This data set has over 2.4 million records with ninety-one columns. \n",
    "\n",
    "As I mentioned earlier in this post, sometimes the same data is hosted on both the county and the city datahubs. This is the case with parcel data. The LA City datahub has two data sets of parcels, <a href=\"https://geohub.lacity.org/datasets/lacounty::parcels\">one with all 2.4 million records</a>, and only the ability to download the file, presumably due to its size, and <a href=\"https://geohub.lacity.org/datasets/la-city-parcels?geometry=-120.986%2C33.625%2C-115.833%2C34.422\">another</a> with just the parcels in LA City. This reduces the record count to 882K, but for some reason this data set has fewer columns. LA City provides an an API to query this data set directly. Unfortunately the one column I was hoping to get, the size of the lot, isn't present. Overall I'm finding that the LA City data hub does a better job of documentation, and given the sometimes unintelligible naming of columns, this can be a great asset. Given that it seems as if LA City has reproduced the complete parcel data set from the county, I choose to source the data from its owner - LA County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:27:53.924626Z",
     "start_time": "2021-04-10T20:27:53.918835Z"
    }
   },
   "outputs": [],
   "source": [
    "# parcels_raw = gpd.read_file('https://opendata.arcgis.com/datasets/6d85cb5f5f5641c6aa95203849ca05bb_0.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note, this is a geojson dataset, so a proper geospatial db, and thus I can query with GeoPandas directly.)\n",
    "\n",
    "I first tried to query the entire 2.4 million records, but after 10 minutes of waiting I halted that exercise.\n",
    "\n",
    "I then used the \"API Explorer\" available on their site to generate a url that will query a reduced number of columns. I change my query to request only seven columns, an object ID, the 5 values of square footage, and the lot size. This should make the request much smaller and indeed it does finish in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:28:02.650494Z",
     "start_time": "2021-04-10T20:27:53.928657Z"
    }
   },
   "outputs": [],
   "source": [
    "parcels_raw = requests.get('https://public.gis.lacounty.gov/public/rest/services/LACounty_Cache/LACounty_Parcel/MapServer/0/query?where=1%3D1&outFields=OBJECTID,APN,SQFTmain1,SQFTmain2,SQFTmain3,SQFTmain4,SQFTmain5,Shape.STArea()&outSR=4326&f=json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:28:02.664329Z",
     "start_time": "2021-04-10T20:28:02.654642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-12T19:28:41.763639Z",
     "start_time": "2021-03-12T19:28:41.748594Z"
    }
   },
   "source": [
    "(Note that the API explorer generates a json file, not a geojson file, probably because the user does not have to include the \"geometry\" column. Thus I do not use GeoPandas but the requests library.)\n",
    "\n",
    "But as I started using it I found that it only downloads 1000 records - just like the Socrata API did with the ADU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:28:02.719687Z",
     "start_time": "2021-04-10T20:28:02.668926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(parcels_raw.json()['features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So its seems that LA City foresaw this problem and thus only allows users to access the data via download and not an API. I decide the best thing to do is download the entire data set to my laptop and load it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:17.886127Z",
     "start_time": "2021-04-10T20:28:02.723954Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,18,28,35,42,49,74,75,76) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2410913 entries, 0 to 2410912\n",
      "Data columns (total 91 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   OBJECTID              int64  \n",
      " 1   AIN                   object \n",
      " 2   APN                   object \n",
      " 3   SitusHouseNo          float64\n",
      " 4   SitusFraction         object \n",
      " 5   SitusDirection        object \n",
      " 6   SitusUnit             object \n",
      " 7   SitusStreet           object \n",
      " 8   SitusAddress          object \n",
      " 9   SitusCity             object \n",
      " 10  SitusZIP              object \n",
      " 11  SitusFullAddress      object \n",
      " 12  TaxRateArea           float64\n",
      " 13  TaxRateCity           object \n",
      " 14  AgencyClassNo         float64\n",
      " 15  AgencyName            object \n",
      " 16  AgencyType            object \n",
      " 17  UseCode               object \n",
      " 18  UseCode_2             object \n",
      " 19  UseType               object \n",
      " 20  UseDescription        object \n",
      " 21  DesignType1           object \n",
      " 22  YearBuilt1            float64\n",
      " 23  EffectiveYear1        float64\n",
      " 24  Units1                float64\n",
      " 25  Bedrooms1             float64\n",
      " 26  Bathrooms1            float64\n",
      " 27  SQFTmain1             float64\n",
      " 28  DesignType2           object \n",
      " 29  YearBuilt2            float64\n",
      " 30  EffectiveYear2        float64\n",
      " 31  Units2                float64\n",
      " 32  Bedrooms2             float64\n",
      " 33  Bathrooms2            float64\n",
      " 34  SQFTmain2             float64\n",
      " 35  DesignType3           object \n",
      " 36  YearBuilt3            float64\n",
      " 37  EffectiveYear3        float64\n",
      " 38  Units3                float64\n",
      " 39  Bedrooms3             float64\n",
      " 40  Bathrooms3            float64\n",
      " 41  SQFTmain3             float64\n",
      " 42  DesignType4           object \n",
      " 43  YearBuilt4            float64\n",
      " 44  EffectiveYear4        float64\n",
      " 45  Units4                float64\n",
      " 46  Bedrooms4             float64\n",
      " 47  Bathrooms4            float64\n",
      " 48  SQFTmain4             float64\n",
      " 49  DesignType5           object \n",
      " 50  YearBuilt5            float64\n",
      " 51  EffectiveYear5        float64\n",
      " 52  Units5                float64\n",
      " 53  Bedrooms5             float64\n",
      " 54  Bathrooms5            float64\n",
      " 55  SQFTmain5             float64\n",
      " 56  Roll_Year             float64\n",
      " 57  Roll_LandValue        float64\n",
      " 58  Roll_ImpValue         float64\n",
      " 59  Roll_PersPropValue    float64\n",
      " 60  Roll_FixtureValue     float64\n",
      " 61  Roll_HomeOwnersExemp  float64\n",
      " 62  Roll_RealEstateExemp  float64\n",
      " 63  Roll_PersPropExemp    float64\n",
      " 64  Roll_FixtureExemp     float64\n",
      " 65  Roll_LandBaseYear     float64\n",
      " 66  Roll_ImpBaseYear      float64\n",
      " 67  SpatialChangeDate     float64\n",
      " 68  ParcelCreateDate      float64\n",
      " 69  ParcelTypeCode        float64\n",
      " 70  Assr_Map              object \n",
      " 71  Assr_Index_Map        object \n",
      " 72  QualityClass1         object \n",
      " 73  QualityClass2         object \n",
      " 74  QualityClass3         object \n",
      " 75  QualityClass4         object \n",
      " 76  QualityClass5         object \n",
      " 77  LegalDescLine1        object \n",
      " 78  LegalDescLine2        object \n",
      " 79  LegalDescLine3        object \n",
      " 80  LegalDescLine4        object \n",
      " 81  LegalDescLine5        object \n",
      " 82  LegalDescLineLast     object \n",
      " 83  LegalDescription      object \n",
      " 84  CENTER_LAT            float64\n",
      " 85  CENTER_LON            float64\n",
      " 86  CENTER_X              float64\n",
      " 87  CENTER_Y              float64\n",
      " 88  LAT_LON               object \n",
      " 89  Shape.STArea()        float64\n",
      " 90  Shape.STLength()      float64\n",
      "dtypes: float64(53), int64(1), object(37)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "parcels_df = pd.read_csv('./data/LA_County_Parcel_Map_Service.csv')\n",
    "parcels_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm only going to the use lot size and the total square footage of all the buildings on the lot, I inspect just those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:18.337477Z",
     "start_time": "2021-04-10T20:29:17.898439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APN</th>\n",
       "      <th>SQFTmain1</th>\n",
       "      <th>SQFTmain2</th>\n",
       "      <th>SQFTmain3</th>\n",
       "      <th>SQFTmain4</th>\n",
       "      <th>SQFTmain5</th>\n",
       "      <th>Shape.STArea()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7102-032-097</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263890.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7102-032-107</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263890.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7103-002-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4858.358398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7103-002-003</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7503.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7103-003-005</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7482.393555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            APN  SQFTmain1  SQFTmain2  SQFTmain3  SQFTmain4  SQFTmain5  \\\n",
       "0  7102-032-097     1122.0        NaN        NaN        NaN        NaN   \n",
       "1  7102-032-107     1361.0        NaN        NaN        NaN        NaN   \n",
       "2  7103-002-001        NaN        NaN        NaN        NaN        NaN   \n",
       "3  7103-002-003     1881.0        NaN        NaN        NaN        NaN   \n",
       "4  7103-003-005     7500.0        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   Shape.STArea()  \n",
       "0   263890.580078  \n",
       "1   263890.580078  \n",
       "2     4858.358398  \n",
       "3     7503.089844  \n",
       "4     7482.393555  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_df[['APN','SQFTmain1','SQFTmain2','SQFTmain3','SQFTmain4','SQFTmain5','Shape.STArea()']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most lots won't have more than one building, and the dataset is carrying null values in those cases, I decide to impute those records with zeros so that I can sum the square footage from every building into one number for my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:18.479894Z",
     "start_time": "2021-04-10T20:29:18.344519Z"
    }
   },
   "outputs": [],
   "source": [
    "parcels_df['SQFTmainTot']=parcels_df['SQFTmain1'].fillna(0)+parcels_df['SQFTmain2'].fillna(0)+\\\n",
    "    parcels_df['SQFTmain3'].fillna(0)+parcels_df['SQFTmain4'].fillna(0)+parcels_df['SQFTmain5'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then save it locally so that I don't have to work from the same monster dataset if I re-run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:40.954077Z",
     "start_time": "2021-04-10T20:29:18.485165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APN</th>\n",
       "      <th>SQFTmainTot</th>\n",
       "      <th>Shape.STArea()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7102-032-097</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>263890.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7102-032-107</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>263890.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7103-002-001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4858.358398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7103-002-003</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>7503.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7103-003-005</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7482.393555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            APN  SQFTmainTot  Shape.STArea()\n",
       "0  7102-032-097       1122.0   263890.580078\n",
       "1  7102-032-107       1361.0   263890.580078\n",
       "2  7103-002-001          0.0     4858.358398\n",
       "3  7103-002-003       1881.0     7503.089844\n",
       "4  7103-003-005       7500.0     7482.393555"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcels_sub = parcels_df[['APN','SQFTmainTot', 'Shape.STArea()']]\n",
    "parcels_sub.to_csv('parcels_sub.csv')\n",
    "parcels_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this clean dataset, let's do a test merge to our ADU data set with median income. I would expect virtually all the records to have a match since the APN's in the ADU data set are all from LA City, and the parcels data should be all parcel in LA County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:43.340000Z",
     "start_time": "2021-04-10T20:29:40.965883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7778 entries, 0 to 7777\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                   Non-Null Count  Dtype   \n",
      "---  ------                                   --------------  -----   \n",
      " 0   zip_code                                 7778 non-null   object  \n",
      " 1   address_end                              7778 non-null   object  \n",
      " 2   work_description                         7778 non-null   object  \n",
      " 3   reference_old_permit                     7778 non-null   object  \n",
      " 4   principal_first_name                     3856 non-null   object  \n",
      " 5   census_tract                             7778 non-null   object  \n",
      " 6   permit_category                          7778 non-null   object  \n",
      " 7   latest_status                            7778 non-null   object  \n",
      " 8   initiating_office                        7778 non-null   object  \n",
      " 9   applicant_first_name                     7639 non-null   object  \n",
      " 10  zone                                     7772 non-null   object  \n",
      " 11  contractor_state                         3608 non-null   object  \n",
      " 12  license_expiration_date                  4749 non-null   object  \n",
      " 13  principal_middle_name                    2411 non-null   object  \n",
      " 14  license_type                             7778 non-null   object  \n",
      " 15  valuation                                7778 non-null   object  \n",
      " 16  pcis_permit                              7778 non-null   object  \n",
      " 17  applicant_relationship                   7651 non-null   object  \n",
      " 18  contractor_city                          3609 non-null   object  \n",
      " 19  address_start                            7778 non-null   object  \n",
      " 20  street_name                              7778 non-null   object  \n",
      " 21  street_suffix                            7692 non-null   object  \n",
      " 22  street_direction                         7739 non-null   object  \n",
      " 23  status_date                              7778 non-null   object  \n",
      " 24  applicant_last_name                      6489 non-null   object  \n",
      " 25  principal_last_name                      3843 non-null   object  \n",
      " 26  license                                  7778 non-null   object  \n",
      " 27  issue_date                               7778 non-null   object  \n",
      " 28  contractors_business_name                7765 non-null   object  \n",
      " 29  tract                                    7759 non-null   object  \n",
      " 30  lot                                      7745 non-null   object  \n",
      " 31  permit_sub_type                          7778 non-null   object  \n",
      " 32  council_district                         7778 non-null   object  \n",
      " 33  contractor_address                       3726 non-null   object  \n",
      " 34  permit_type                              7778 non-null   object  \n",
      " 35  applicant_address_1                      5383 non-null   object  \n",
      " 36  applicant_address_3                      5111 non-null   object  \n",
      " 37  applicant_address_2                      1318 non-null   object  \n",
      " 38  unit_range_start                         72 non-null     object  \n",
      " 39  floor_area_l_a_building_code_definition  4337 non-null   object  \n",
      " 40  of_residential_dwelling_units            1896 non-null   object  \n",
      " 41  floor_area_l_a_zoning_code_definition    4122 non-null   object  \n",
      " 42  of_stories                               4017 non-null   object  \n",
      " 43  applicant_business_name                  543 non-null    object  \n",
      " 44  address_fraction_start                   234 non-null    object  \n",
      " 45  address_fraction_end                     321 non-null    object  \n",
      " 46  occupancy                                113 non-null    object  \n",
      " 47  block                                    1470 non-null   object  \n",
      " 48  unit_range_end                           5 non-null      object  \n",
      " 49  project_number                           5 non-null      object  \n",
      " 50  suffix_direction                         7 non-null      object  \n",
      " 51  APN                                      7778 non-null   object  \n",
      " 52  latitude                                 6773 non-null   float64 \n",
      " 53  longitude                                6773 non-null   float64 \n",
      " 54  median_income                            7776 non-null   object  \n",
      " 55  SQFTmainTot                              7450 non-null   float64 \n",
      " 56  Shape.STArea()                           7450 non-null   float64 \n",
      " 57  _merge                                   7778 non-null   category\n",
      "dtypes: category(1), float64(4), object(53)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test = pd.merge(data_df, parcels_sub, on='APN', how='left', indicator=True)\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 7778 - 7450 = 328 records in the ADU dataset that don't have a match in the parcel dataset. Not terrible but peculiar. About half of them are unique so it looks like there could be multiple permits for the same lot, or simply input errors with the APN.\n",
    " \n",
    "Let's take a look at those records in the ADU data set whose APN did not match to any APN in the parcels data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:43.378231Z",
     "start_time": "2021-04-10T20:29:43.345265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          7450\n",
       "left_only      328\n",
       "right_only       0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:43.399331Z",
     "start_time": "2021-04-10T20:29:43.384349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test['_merge']=='left_only']['APN'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that only about half the records are unique. This seems a little funny. I'm going to do some spot checking to see if anything else jumps out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:43.422135Z",
     "start_time": "2021-04-10T20:29:43.405039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7671    2527-011-031\n",
       "7678    5569-037-001\n",
       "7680    2355-018-026\n",
       "7709    5485-006-002\n",
       "7716    5442-002-919\n",
       "7746    4409-005-023\n",
       "7747    4369-001-014\n",
       "7750    4494-022-030\n",
       "7752    4409-005-021\n",
       "7763    4369-001-014\n",
       "Name: APN, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I chose tail just to mix it up.\n",
    "test[test['_merge']=='left_only']['APN'].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now pick one randomly and try to match it to a record in the parcels data set by address instead of APN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:43.451514Z",
     "start_time": "2021-04-10T20:29:43.426594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_start</th>\n",
       "      <th>street_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7746</th>\n",
       "      <td>1105</td>\n",
       "      <td>RIVAS CANYON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     address_start   street_name\n",
       "7746          1105  RIVAS CANYON"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query this one record for its street address\n",
    "test[test['APN']=='4409-005-023'][['address_start', 'street_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:49.709405Z",
     "start_time": "2021-04-10T20:29:43.463739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1105 RIVAS CANYON ROAD\n"
     ]
    }
   ],
   "source": [
    "# Now check the parcels data set for addresses that have these elements using a regex\n",
    "for x in parcels_df['SitusAddress']:\n",
    "    if re.search('1105 RIVAS CANYON', str(x)):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:50.252883Z",
     "start_time": "2021-04-10T20:29:49.712676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>AIN</th>\n",
       "      <th>APN</th>\n",
       "      <th>SitusHouseNo</th>\n",
       "      <th>SitusFraction</th>\n",
       "      <th>SitusDirection</th>\n",
       "      <th>SitusUnit</th>\n",
       "      <th>SitusStreet</th>\n",
       "      <th>SitusAddress</th>\n",
       "      <th>SitusCity</th>\n",
       "      <th>...</th>\n",
       "      <th>LegalDescLineLast</th>\n",
       "      <th>LegalDescription</th>\n",
       "      <th>CENTER_LAT</th>\n",
       "      <th>CENTER_LON</th>\n",
       "      <th>CENTER_X</th>\n",
       "      <th>CENTER_Y</th>\n",
       "      <th>LAT_LON</th>\n",
       "      <th>Shape.STArea()</th>\n",
       "      <th>Shape.STLength()</th>\n",
       "      <th>SQFTmainTot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1571134</th>\n",
       "      <td>1571135</td>\n",
       "      <td>4409005030</td>\n",
       "      <td>4409-005-030</td>\n",
       "      <td>1105.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RIVAS CANYON ROAD</td>\n",
       "      <td>1105 RIVAS CANYON ROAD</td>\n",
       "      <td>PACIFIC PALISADES</td>\n",
       "      <td>...</td>\n",
       "      <td>DESC SEE ASSESSOR'S MAPS POR OF LOT 40</td>\n",
       "      <td>OFFICIAL MAP OF LOS ANGELES COUNTY FOR DESC SE...</td>\n",
       "      <td>34.04981</td>\n",
       "      <td>-118.516282</td>\n",
       "      <td>6.405275e+06</td>\n",
       "      <td>1.840911e+06</td>\n",
       "      <td>34.049810, -118.516282</td>\n",
       "      <td>83450.136719</td>\n",
       "      <td>1215.682444</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OBJECTID         AIN           APN  SitusHouseNo SitusFraction  \\\n",
       "1571134   1571135  4409005030  4409-005-030        1105.0                 \n",
       "\n",
       "        SitusDirection SitusUnit        SitusStreet            SitusAddress  \\\n",
       "1571134                           RIVAS CANYON ROAD  1105 RIVAS CANYON ROAD   \n",
       "\n",
       "                 SitusCity  ...                       LegalDescLineLast  \\\n",
       "1571134  PACIFIC PALISADES  ...  DESC SEE ASSESSOR'S MAPS POR OF LOT 40   \n",
       "\n",
       "                                          LegalDescription  CENTER_LAT  \\\n",
       "1571134  OFFICIAL MAP OF LOS ANGELES COUNTY FOR DESC SE...    34.04981   \n",
       "\n",
       "         CENTER_LON      CENTER_X      CENTER_Y                 LAT_LON  \\\n",
       "1571134 -118.516282  6.405275e+06  1.840911e+06  34.049810, -118.516282   \n",
       "\n",
       "        Shape.STArea() Shape.STLength() SQFTmainTot  \n",
       "1571134   83450.136719      1215.682444     10000.0  \n",
       "\n",
       "[1 rows x 92 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now take the full street address and filter the parcels data set for its APN\n",
    "parcels_df[parcels_df['SitusAddress']=='1105 RIVAS CANYON ROAD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we see that the APN for this address in the county data set is 4409-005-030, while its 4409-005-023 in the LA City ADU data set.\n",
    "\n",
    "After having done this a few times it seems that the APN is incorrect in either the ADU data set or the parcels data set.\n",
    "\n",
    "At this point I'm going to leave the 328 records unmatched. If I thought that the lot size feature would be a strong contributor to the predictive accuracy of the model I want to build, or if I find later that it is, I would add address as a match criteria. At this point I going to go with it as is since 328 records is only about 4% of the ADU records.\n",
    "\n",
    "Let's go ahead and merge the parcel data on the the ADU data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:52.995233Z",
     "start_time": "2021-04-10T20:29:50.259781Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.merge(data_df, parcels_sub, on='APN', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then clean up some of the naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:53.060455Z",
     "start_time": "2021-04-10T20:29:53.011320Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.rename(columns={'SQFTmainTot':'building_size', 'Shape.STArea()':'lot_size'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then I'm going to create a column of the land size minus the building size to represent just the open space on the lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:29:53.115083Z",
     "start_time": "2021-04-10T20:29:53.090539Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df['open_land']=data_df['lot_size']-data_df['building_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data and Joining on Geometries\n",
    "The third type of data we want to add is an indicator if the lot was on a hillside. The radio story mentioned earlier in this post suggested that hillside can be quite difficult to build on. I found an interesting <a href=\"https://buildcover.com/updates/las-proposed-hillside-adu-ban\">blog post</a> from a company that manufactures pre-fabricated ADU's which was also warning of new hillside construction ordinances going into effect in Los Angeles.\n",
    "\n",
    "In the LA City data hub a <a href=\"https://geohub.lacity.org/datasets/hillside-ordinance\">geospatial dataset</a> of these areas already existed. We can use this to tag every record in the ADU data set as being on a hillside or not. This represents another way of merging data together - a spatial join. For this we are going to use the GeoPandas library to determine if the location of the project lies within the boundaries of a hillside. This type of spatial join is referred to as a point in polygon. \n",
    "\n",
    "So let's first download the hillside dataset. Since its a geospatial database, we can simply read the geojson file into a GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:01.594142Z",
     "start_time": "2021-04-10T20:29:53.136172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   H_TYPE    344 non-null    object  \n",
      " 1   OBJECTID  344 non-null    int64   \n",
      " 2   TOOLTIP   344 non-null    object  \n",
      " 3   geometry  344 non-null    geometry\n",
      "dtypes: geometry(1), int64(1), object(2)\n",
      "memory usage: 10.9+ KB\n"
     ]
    }
   ],
   "source": [
    "hills_gdf = gpd.read_file('https://opendata.arcgis.com/datasets/3ac07567df1c4f3b916ac258e426e3f5_6.geojson')\n",
    "hills_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, a mere 344 records, so this loaded like a breeze.\n",
    "\n",
    "Before we merge this data set to the ADU data set we have to first convert the longitude and latitude columns in the ADU data set into a proper geospatial element, and define the projection. The projection is the crs, or coordinate reference system, that is used to project a round shape like the planet onto a flat surface that is a map. We'll use the crs of the hillside data set, since they must match to properly merge on the geometry features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:01.741852Z",
     "start_time": "2021-04-10T20:30:01.609241Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert the ADU data set to a GeoDataFrame with GeoPandas and create a point geometry from the lat-long columns\n",
    "data_gdf = gpd.GeoDataFrame(data_df, geometry=gpd.points_from_xy(data_df.longitude, data_df.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:01.750630Z",
     "start_time": "2021-04-10T20:30:01.746775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign it the same crs as the hillside data set\n",
    "data_gdf.crs = hills_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:01.774443Z",
     "start_time": "2021-04-10T20:30:01.756426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete some unnessary columns\n",
    "del hills_gdf['OBJECTID']\n",
    "del hills_gdf['TOOLTIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:02.956599Z",
     "start_time": "2021-04-10T20:30:01.780452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 7778 entries, 0 to 7777\n",
      "Data columns (total 61 columns):\n",
      " #   Column                                   Non-Null Count  Dtype   \n",
      "---  ------                                   --------------  -----   \n",
      " 0   zip_code                                 7778 non-null   object  \n",
      " 1   address_end                              7778 non-null   object  \n",
      " 2   work_description                         7778 non-null   object  \n",
      " 3   reference_old_permit                     7778 non-null   object  \n",
      " 4   principal_first_name                     3856 non-null   object  \n",
      " 5   census_tract                             7778 non-null   object  \n",
      " 6   permit_category                          7778 non-null   object  \n",
      " 7   latest_status                            7778 non-null   object  \n",
      " 8   initiating_office                        7778 non-null   object  \n",
      " 9   applicant_first_name                     7639 non-null   object  \n",
      " 10  zone                                     7772 non-null   object  \n",
      " 11  contractor_state                         3608 non-null   object  \n",
      " 12  license_expiration_date                  4749 non-null   object  \n",
      " 13  principal_middle_name                    2411 non-null   object  \n",
      " 14  license_type                             7778 non-null   object  \n",
      " 15  valuation                                7778 non-null   object  \n",
      " 16  pcis_permit                              7778 non-null   object  \n",
      " 17  applicant_relationship                   7651 non-null   object  \n",
      " 18  contractor_city                          3609 non-null   object  \n",
      " 19  address_start                            7778 non-null   object  \n",
      " 20  street_name                              7778 non-null   object  \n",
      " 21  street_suffix                            7692 non-null   object  \n",
      " 22  street_direction                         7739 non-null   object  \n",
      " 23  status_date                              7778 non-null   object  \n",
      " 24  applicant_last_name                      6489 non-null   object  \n",
      " 25  principal_last_name                      3843 non-null   object  \n",
      " 26  license                                  7778 non-null   object  \n",
      " 27  issue_date                               7778 non-null   object  \n",
      " 28  contractors_business_name                7765 non-null   object  \n",
      " 29  tract                                    7759 non-null   object  \n",
      " 30  lot                                      7745 non-null   object  \n",
      " 31  permit_sub_type                          7778 non-null   object  \n",
      " 32  council_district                         7778 non-null   object  \n",
      " 33  contractor_address                       3726 non-null   object  \n",
      " 34  permit_type                              7778 non-null   object  \n",
      " 35  applicant_address_1                      5383 non-null   object  \n",
      " 36  applicant_address_3                      5111 non-null   object  \n",
      " 37  applicant_address_2                      1318 non-null   object  \n",
      " 38  unit_range_start                         72 non-null     object  \n",
      " 39  floor_area_l_a_building_code_definition  4337 non-null   object  \n",
      " 40  of_residential_dwelling_units            1896 non-null   object  \n",
      " 41  floor_area_l_a_zoning_code_definition    4122 non-null   object  \n",
      " 42  of_stories                               4017 non-null   object  \n",
      " 43  applicant_business_name                  543 non-null    object  \n",
      " 44  address_fraction_start                   234 non-null    object  \n",
      " 45  address_fraction_end                     321 non-null    object  \n",
      " 46  occupancy                                113 non-null    object  \n",
      " 47  block                                    1470 non-null   object  \n",
      " 48  unit_range_end                           5 non-null      object  \n",
      " 49  project_number                           5 non-null      object  \n",
      " 50  suffix_direction                         7 non-null      object  \n",
      " 51  APN                                      7778 non-null   object  \n",
      " 52  latitude                                 6773 non-null   float64 \n",
      " 53  longitude                                6773 non-null   float64 \n",
      " 54  median_income                            7776 non-null   object  \n",
      " 55  building_size                            7450 non-null   float64 \n",
      " 56  lot_size                                 7450 non-null   float64 \n",
      " 57  open_land                                7450 non-null   float64 \n",
      " 58  geometry                                 7778 non-null   geometry\n",
      " 59  index_right                              1694 non-null   float64 \n",
      " 60  H_TYPE                                   1694 non-null   object  \n",
      "dtypes: float64(6), geometry(1), object(54)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# With the spatial joing method of GeoPandas merge the hills_gdf GeoDataFrame onto the data_gdf GeoDataFrame\n",
    "data_gdf = gpd.sjoin(data_gdf, hills_gdf, how='left', op=\"within\")\n",
    "data_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like 1694 records in our ADU data set are on a hillside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:02.969560Z",
     "start_time": "2021-04-10T20:30:02.961295Z"
    }
   },
   "outputs": [],
   "source": [
    "del data_gdf['index_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:02.981822Z",
     "start_time": "2021-04-10T20:30:02.973622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename the hillside tag column to something more readable\n",
    "data_gdf.rename(columns={'H_TYPE':'hillside'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:03.012194Z",
     "start_time": "2021-04-10T20:30:02.985437Z"
    }
   },
   "outputs": [],
   "source": [
    "# And now let's clean up the actual tag values so they are simply '1' is the record is of a hillside location\n",
    "data_gdf['hillside']=data_gdf['hillside'].apply(lambda x: int(1) if isinstance(x,str) else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out merging the geospatial data into the ADU data set was the easier than the key word merges. Of course I'm not doing the say validation in this merge as I did with the others. One could geo-locate the address of every ADU record, create a point with a buffer around, and then check to see if the lat-long data provided in the ADU dataset actually falls within the buffer. In a production setting where the validity of the locations is critical I would write a function that does this, but for the purpose of what I wanted to accomplish here, what we've done should be sufficient.\n",
    "\n",
    "So we've gone through an example of assembling a data set of building permit data from the city of Los Angeles, parcel details from the county of Los Angeles, demographic data from the US Census and geospatial data from the city. We've also seen how to merge data set on a key, check the validity of the key itself, and how to perform a spatial join to include regional characteristics in a data set. This covers many of the situations you would need to build an interesting data set from multiple sources to address civic issues in the city of Los Angeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:03.111109Z",
     "start_time": "2021-04-10T20:30:03.016319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 7778 entries, 0 to 7777\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                   Non-Null Count  Dtype   \n",
      "---  ------                                   --------------  -----   \n",
      " 0   zip_code                                 7778 non-null   object  \n",
      " 1   address_end                              7778 non-null   object  \n",
      " 2   work_description                         7778 non-null   object  \n",
      " 3   reference_old_permit                     7778 non-null   object  \n",
      " 4   principal_first_name                     3856 non-null   object  \n",
      " 5   census_tract                             7778 non-null   object  \n",
      " 6   permit_category                          7778 non-null   object  \n",
      " 7   latest_status                            7778 non-null   object  \n",
      " 8   initiating_office                        7778 non-null   object  \n",
      " 9   applicant_first_name                     7639 non-null   object  \n",
      " 10  zone                                     7772 non-null   object  \n",
      " 11  contractor_state                         3608 non-null   object  \n",
      " 12  license_expiration_date                  4749 non-null   object  \n",
      " 13  principal_middle_name                    2411 non-null   object  \n",
      " 14  license_type                             7778 non-null   object  \n",
      " 15  valuation                                7778 non-null   object  \n",
      " 16  pcis_permit                              7778 non-null   object  \n",
      " 17  applicant_relationship                   7651 non-null   object  \n",
      " 18  contractor_city                          3609 non-null   object  \n",
      " 19  address_start                            7778 non-null   object  \n",
      " 20  street_name                              7778 non-null   object  \n",
      " 21  street_suffix                            7692 non-null   object  \n",
      " 22  street_direction                         7739 non-null   object  \n",
      " 23  status_date                              7778 non-null   object  \n",
      " 24  applicant_last_name                      6489 non-null   object  \n",
      " 25  principal_last_name                      3843 non-null   object  \n",
      " 26  license                                  7778 non-null   object  \n",
      " 27  issue_date                               7778 non-null   object  \n",
      " 28  contractors_business_name                7765 non-null   object  \n",
      " 29  tract                                    7759 non-null   object  \n",
      " 30  lot                                      7745 non-null   object  \n",
      " 31  permit_sub_type                          7778 non-null   object  \n",
      " 32  council_district                         7778 non-null   object  \n",
      " 33  contractor_address                       3726 non-null   object  \n",
      " 34  permit_type                              7778 non-null   object  \n",
      " 35  applicant_address_1                      5383 non-null   object  \n",
      " 36  applicant_address_3                      5111 non-null   object  \n",
      " 37  applicant_address_2                      1318 non-null   object  \n",
      " 38  unit_range_start                         72 non-null     object  \n",
      " 39  floor_area_l_a_building_code_definition  4337 non-null   object  \n",
      " 40  of_residential_dwelling_units            1896 non-null   object  \n",
      " 41  floor_area_l_a_zoning_code_definition    4122 non-null   object  \n",
      " 42  of_stories                               4017 non-null   object  \n",
      " 43  applicant_business_name                  543 non-null    object  \n",
      " 44  address_fraction_start                   234 non-null    object  \n",
      " 45  address_fraction_end                     321 non-null    object  \n",
      " 46  occupancy                                113 non-null    object  \n",
      " 47  block                                    1470 non-null   object  \n",
      " 48  unit_range_end                           5 non-null      object  \n",
      " 49  project_number                           5 non-null      object  \n",
      " 50  suffix_direction                         7 non-null      object  \n",
      " 51  APN                                      7778 non-null   object  \n",
      " 52  latitude                                 6773 non-null   float64 \n",
      " 53  longitude                                6773 non-null   float64 \n",
      " 54  median_income                            7776 non-null   object  \n",
      " 55  building_size                            7450 non-null   float64 \n",
      " 56  lot_size                                 7450 non-null   float64 \n",
      " 57  open_land                                7450 non-null   float64 \n",
      " 58  geometry                                 7778 non-null   geometry\n",
      " 59  hillside                                 1694 non-null   float64 \n",
      "dtypes: float64(6), geometry(1), object(53)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together into an ETL class\n",
    "And with that we've create a dataset on which to begin the modeling process. But, first lets pull everything we've done into a single function that can be imported into any other notebooks and use to create a working data set. I'm going to write the code so that it can pull the large parcel data from disk since we found that using the API to download even a fraction of it directly into memory wasn't feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-10T20:30:03.183506Z",
     "start_time": "2021-04-10T20:30:03.119247Z"
    }
   },
   "outputs": [],
   "source": [
    "class ETL:\n",
    "    def __init__(self, la_city_database, la_city_usrn, la_city_psswrd, la_city_token, limit=8000):\n",
    "        self.la_city_database = la_city_database,\n",
    "        self.la_city_usrn = la_city_usrn,\n",
    "        self.la_city_psswrd = la_city_psswrd,\n",
    "        self.la_city_token = la_city_token\n",
    "        with open(la_city_token, 'r') as f:\n",
    "            api_token = f.readline().replace('\\n','')\n",
    "        with open(la_city_usrn, 'r') as f:\n",
    "            usrn = f.readline().replace('\\n','')\n",
    "        with open(la_city_psswrd, 'r') as f:\n",
    "            psswrd = f.readline().replace('\\n','')\n",
    "        self.client = Socrata('data.lacity.org', api_token, username=usrn, password=psswrd)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Query for database {self.la_city_database[0]}'\n",
    "    \n",
    "    # Create getters and setters for class attributes\n",
    "    @property\n",
    "    def la_city_database(self):\n",
    "        return self._la_city_database\n",
    "    \n",
    "    @la_city_database.setter\n",
    "    def la_city_database(self, la_city_database):\n",
    "        if not isinstance(la_city_database[0], str):\n",
    "            raise ValueError('\"la_city_database\" must be a string.')\n",
    "        self._la_city_database = la_city_database[0]\n",
    "    \n",
    "    @property\n",
    "    def la_city_usrn(self):\n",
    "        return self._la_city_usrn\n",
    "    \n",
    "    @la_city_database.setter\n",
    "    def la_city_usrn(self, la_city_usrn):\n",
    "        if not isinstance(la_city_usrn[0], str):\n",
    "            raise ValueError('\"la_city_usrn\" must be the path to your LA City Datahub username in str format.')\n",
    "        self._la_city_usrn = la_city_usrn[0]\n",
    "    \n",
    "    @property\n",
    "    def la_city_psswrd(self):\n",
    "        return self._la_city_psswrd\n",
    "    \n",
    "    @la_city_database.setter\n",
    "    def la_city_psswrd(self, la_city_psswrd):\n",
    "        if not isinstance(la_city_psswrd[0], str):\n",
    "            raise ValueError('\"la_city_psswrd\" must be the path to your LA City Datahub password in str format.')\n",
    "        self._la_city_psswrd = la_city_psswrd[0]\n",
    "    \n",
    "    @property\n",
    "    def la_city_token(self):\n",
    "        return self._la_city_token\n",
    "    \n",
    "    @la_city_token.setter\n",
    "    def la_city_token(self, la_city_token):\n",
    "        if not isinstance(la_city_token[0], str):\n",
    "            raise ValueError('\"la_city_token\" must be a the path to your LA City Datahub token in str format.')\n",
    "        self._la_city_token = la_city_token[0]\n",
    "        \n",
    "    def get_records(self):\n",
    "        self.record_count = self.client.get(self.la_city_database, select=\"COUNT(*)\")\n",
    "        return self.record_count\n",
    "        \n",
    "    def get_data(self):\n",
    "        self.data_raw = self.client.get(self.la_city_database, limit=8000)\n",
    "        self.data_df = pd.DataFrame(self.data_raw)\n",
    "        return self.data_df\n",
    "        \n",
    "    def clean_data(self, data):\n",
    "        data_pdf = data.copy()\n",
    "        \n",
    "        # Delete columns starting with ':@'\n",
    "        bad_cols = [x for x in data_pdf.columns if re.search(':@', str(x))]\n",
    "        for col in bad_cols:\n",
    "            del data_pdf[col]\n",
    "        \n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: x.replace('.', ''))\n",
    "        \n",
    "        # Create one APN column\n",
    "        data_pdf['APN'] = data_pdf['assessor_book']+'-'+data_pdf['assessor_page']+'-'+data_pdf['assessor_parcel']\n",
    "        del data_pdf['assessor_book']\n",
    "        del data_pdf['assessor_page']\n",
    "        del data_pdf['assessor_parcel']\n",
    "        \n",
    "        # Extract latitude and longitude into separate columns\n",
    "        data_pdf['latitude'] = data_pdf['location_1'].apply(lambda x: x['latitude'] if isinstance(x, dict) else None)\n",
    "        data_pdf['latitude'] = data_pdf['latitude'].astype(float)\n",
    "        data_pdf['longitude'] = data_pdf['location_1'].apply(lambda x: x['longitude'] if isinstance(x, dict) else None)\n",
    "        data_pdf['longitude'] = data_pdf['longitude'].astype(float)\n",
    "        del data_pdf['location_1']\n",
    "        \n",
    "        # Fix errors in census_tract\n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: '137000' if x=='930401' else x)\n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: '192410' if x=='192400' else x)\n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: '219902' if x=='219900' else x)\n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: '195903' if x=='195900' else x)\n",
    "        data_pdf['census_tract'] = data_pdf['census_tract'].apply(lambda x: '269601' if x=='269600' else x)\n",
    "        \n",
    "        return data_pdf\n",
    "            \n",
    "    def median_income(self, data):\n",
    "        data_pdf = data.copy()\n",
    "        \n",
    "        url='https://api.census.gov/data/2019/acs/acs5?get=B19013_001E&for=tract:*&in=state:06&in=county:037'\n",
    "        median_income_raw = requests.get(url)\n",
    "        median_income_df = pd.DataFrame(data=median_income_raw.json()[1:], columns=median_income_raw.json()[:1][0])\n",
    "        median_income_df.rename(columns={'B19013_001E':'median_income','tract':'census_tract'}, inplace=True)\n",
    "        del median_income_df['state']\n",
    "        del median_income_df['county']\n",
    "        data_pdf = pd.merge(data_pdf, median_income_df, on='census_tract', how='left')\n",
    "        \n",
    "        return data_pdf\n",
    "    \n",
    "    def parcels(self, data, parcels_loc):\n",
    "        data_pdf = data.copy()\n",
    "        \n",
    "        parcels_df = pd.read_csv(parcels_loc)\n",
    "        parcels_df['SQFTmainTot']=parcels_df['SQFTmain1'].fillna(0)+parcels_df['SQFTmain2'].fillna(0)+\\\n",
    "            parcels_df['SQFTmain3'].fillna(0)+parcels_df['SQFTmain4'].fillna(0)+parcels_df['SQFTmain5'].fillna(0)\n",
    "        parcels_sub = parcels_df[['APN','SQFTmainTot', 'Shape.STArea()']]\n",
    "        data_pdf = pd.merge(data_pdf, parcels_sub, on='APN', how='left')\n",
    "        data_pdf.rename(columns={'SQFTmainTot':'building_size', 'Shape.STArea()':'lot_size'}, inplace=True)\n",
    "        data_pdf['open_land']=data_pdf['lot_size']-data_pdf['building_size']\n",
    "        \n",
    "        return data_pdf\n",
    "    \n",
    "    def hillsides(self, data):\n",
    "        data_pdf = data.copy()\n",
    "        \n",
    "        hills_gdf = gpd.read_file('https://opendata.arcgis.com/datasets/3ac07567df1c4f3b916ac258e426e3f5_6.geojson')\n",
    "        data_gdf = gpd.GeoDataFrame(data_pdf, geometry=gpd.points_from_xy(data_pdf.longitude, data_pdf.latitude))\n",
    "        data_gdf.crs = hills_gdf.crs\n",
    "        del hills_gdf['OBJECTID']\n",
    "        del hills_gdf['TOOLTIP']\n",
    "        data_gdf = gpd.sjoin(data_gdf, hills_gdf, how='left', op=\"within\")\n",
    "        del data_gdf['index_right']\n",
    "        del hills_gdf['latitude']\n",
    "        del hills_gdf['longitude']\n",
    "        data_gdf.rename(columns={'H_TYPE':'hillside'}, inplace=True)\n",
    "        data_gdf['hillside']=data_gdf['hillside'].apply(lambda x: int(1) if isinstance(x,str) else np.nan)\n",
    "        \n",
    "        return data_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "343.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
